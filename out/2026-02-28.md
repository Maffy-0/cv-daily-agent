# Daily CV Digest (2026-02-28)

- Total: 2

## 1. Towards Long-Form Spatio-Temporal Video Grounding
- arXiv: http://arxiv.org/abs/2602.23294v1
- PDF: https://arxiv.org/pdf/2602.23294v1
- Authors: Xin Gu, Bing Fan, Jiali Yao, Zhipeng Zhang, Yan Huang, Cheng Han, Heng Fan, Libo Zhang
- Keyword score: 2 / hits: temporal localization, streaming

<details><summary>Abstract</summary>

In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.

</details>

**LLM Summary**

- What: 長時間の動画におけるテキストクエリに対応する物体検出（Long-Form Spatio-Temporal Video Grounding: LF-STVG）を提案し、ストリーミング入力として動画を処理するAutoRegressive Transformerアーキテクチャ（ART-STVG）を開発した。
- Novelty: 長時間動画に対応するため、フレームを逐次処理し、空間的・時間的コンテキストを捉えるためのメモリバンクと選択戦略を導入した。
- Why it matters: 数分から数時間におよぶ長時間の動画コンテンツにおける物体検出の精度と効率を向上させ、現実世界の応用を可能にする。

## 2. Physics Informed Viscous Value Representations
- arXiv: http://arxiv.org/abs/2602.23280v1
- PDF: https://arxiv.org/pdf/2602.23280v1
- Authors: Hrishikesh Viswanath, Juanwu Lu, S. Talha Bukhari, Damon Conover, Ziran Wang, Aniket Bera
- Keyword score: 1 / hits: reinforcement learning

<details><summary>Abstract</summary>

Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.

</details>

**LLM Summary**

- What: オフライン強化学習における価値推定の課題に対し、ハミルトン・ヤコビ・ベルマン（HJB）方程式の粘性解に基づいた物理情報付き正則化手法を提案した。
- Novelty: 従来のPDE正則化の ill-posedness を回避し、Feynman-Kac定理を用いて期待値としてPDE解を捉え、モンテカルロ推定による数値的安定性を向上させた。
- Why it matters: 複雑な高次元環境におけるオフライン強化学習の価値推定精度を向上させ、幾何学的整合性を改善し、より堅牢な学習を可能にする。
